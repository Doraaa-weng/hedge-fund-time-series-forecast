# 时间序列预测项目 - 逻辑与内容介绍

## 一、项目是做什么的？

这是一个 **Kaggle 时间序列预测竞赛** 的项目。  
简单说就是：  
用历史数据训练一个模型，让模型学会「根据过去预测未来」的规律，然后对测试集里的时间点做出预测，最后把预测结果提交到 Kaggle 上打分。

---

## 二、整体流程（逻辑）

```
数据 → 特征工程 → 训练模型 → 评估 → 对测试集预测 → 生成提交文件
```

1. **读数据**：读入 `train.parquet`（训练）和 `test.parquet`（测试）。
2. **特征工程**：把原始列变成模型更好用的特征（滞后、滚动统计等）。
3. **训练模型**：用训练集的特征和标签（y_target）训练一个回归模型。
4. **评估**：在验证集上算 MAE、RMSE 等指标，看模型好不好。
5. **预测**：用训练好的模型对测试集做预测。
6. **提交**：把预测结果写成 `submission.csv`，上传到 Kaggle。

---

## 三、数据长什么样？

- **训练集**：约 533 万行，94 列  
  - 每行 = 某一个时间序列在某个时间点、某个预测步长（horizon）的一条记录。  
  - 重要列：`id`、`code`、`sub_code`、`sub_category`、`horizon`、`ts_index`、很多 `feature_*`、**`y_target`（要预测的值）**、`weight`。
- **测试集**：约 144 万行，92 列（没有 `y_target` 和 `weight`，因为要你来预测）。

**时间序列**：  
- 用 `code + sub_code + sub_category` 可以唯一确定一条时间序列（ts_id）。  
- 一共有 9270 条不同的时间序列。  
- `horizon`：预测 1 / 3 / 10 / 25 步之后的值。  
- `ts_index`：时间步的编号（1～3601 等）。

---

## 四、各个文件在干什么？

### 1. 配置文件：`config.py`

- 放**路径、超参数、特征工程参数**等。
- 例如：训练/测试数据路径、滞后阶数 `LAG_FEATURES`、滚动窗口 `ROLLING_WINDOWS`、验证集比例、模型参数等。
- 改这里就能统一调整「用哪些特征、模型怎么训练」，不用到处改代码。

### 2. 工具函数：`utils.py`

- **create_ts_id**：根据 code/sub_code/sub_category 生成每条时间序列的 id（ts_id）。  
- **create_lag_features**：按 ts_id 分组，对某一列做滞后 1、3、7、14、30 等，得到「过去第 1 步、第 3 步…」的值。  
- **create_rolling_features**：按 ts_id 分组，做滚动窗口的 mean/std/min/max（窗口 7、14、30 等）。  
- **handle_missing_values**：缺失值填充（如用中位数）。  
- **prepare_features**：从整张表里选出「特征列」和「标签列」，去掉 id、weight 等，必要时做 one-hot。  
- **temporal_train_test_split**：按时间序列、按时间顺序划分训练/验证集（防止用未来信息）。  
- **calculate_metrics**：计算 MAE、RMSE、MAPE 等。

这些函数被 `feature_engineering.py` 和训练/预测脚本反复调用。

### 3. 特征工程：`feature_engineering.py`

- **主函数：engineer_features(df, is_train, target_col)**  
  - 先 `create_ts_id`，再按 `ts_id`、`ts_index` 排序。  
  - 若是训练集且有 `y_target`：  
    - 对 `y_target` 做滞后特征（1,3,7,14,30）和滚动特征（7/14/30 窗口的 mean/std/min/max）。  
  - 对少数几列原始特征（如 feature_b, feature_c, feature_d）也做滞后 1/3/7。  
  - 根据 `horizon` 生成 horizon_1 / horizon_3 / horizon_10 / horizon_25 等 0/1 特征。  
  - 对 `ts_index` 做按序列的归一化（ts_index_norm）。  
  - 最后用 `handle_missing_values` 填缺失。  

训练和测试都会调用这个函数，保证「训练时用的特征类型」和「测试时用的」一致。

### 4. 模型定义：`models.py`

- **TimeSeriesModel**：基类，定义 train / predict / get_feature_importance。  
- **LightGBMModel**：用 LightGBM 做回归；若环境没装 LightGBM 会报错或跳过。  
- **XGBoostModel**：用 XGBoost 做回归；同样可选。  
- **GradientBoostingModel**：用 sklearn 的 GradientBoostingRegressor，**不依赖 LightGBM/XGBoost**，所以是默认可用的模型。  

训练时会把「特征 X」和「标签 y」喂给这些模型，支持按 `weight` 加权。

### 5. 训练脚本

- **train_quick.py**（快速版）  
  - 读入训练数据 → 调用 **engineer_features** 做特征 → 只保留约 1000 条时间序列做采样 → 80/20 划分训练/验证 → 用 **GradientBoostingModel** 训练 → 算验证集 MAE/RMSE 和特征重要性 → 把模型存成 `gradient_boosting_model.pkl`（同时复制一份为 `lightgbm_model.pkl` 方便 predict 脚本用）。  

- **train.py**（完整版）  
  - 同样：读数据 → engineer_features → 按 ts_id 做**时间顺序**的 train/val 划分（最后 20% 时间做验证）→ 优先尝试 LightGBM，失败则用 GradientBoostingModel → 评估并保存模型和结果。  
  - 数据量大，跑得会慢很多。

### 6. 预测脚本：`predict.py`

- 读测试集 → 调用 **engineer_features(test, is_train=False)**（测试集没有 y_target，所以不会做基于 y_target 的滞后/滚动，但会做 ts_id、horizon、ts_index_norm、缺失值等）。  
- 用 **prepare_features** 得到和训练时一致的特征列（且对齐列名和类型）。  
- 加载保存的模型（如 `lightgbm_model.pkl`）→ 对测试集 predict → 结果限制在合理区间（如 -2500～2500）→ 写出 **submission.csv**（至少包含 id 和预测的 y_target）。

### 7. 外壳脚本：`run_train_quick.sh`、`run_train.sh`、`run_predict.sh`

- 用 **/usr/bin/python3** 调用对应的 py 脚本，避免用 conda 环境下没装齐包的 python。  
- 你只要在终端执行 `./run_train_quick.sh` 或 `./run_train.sh`、`./run_predict.sh` 即可。

---

## 五、逻辑串联（谁调谁）

```
run_train_quick.sh
  → train_quick.py
      → config（路径、参数）
      → 读 train.parquet
      → feature_engineering.engineer_features（用 utils 里的 create_ts_id, lag, rolling, handle_missing）
      → utils.prepare_features（得到 X, y）
      → models.GradientBoostingModel.train
      → utils.calculate_metrics
      → 保存 .pkl

run_predict.sh
  → predict.py
      → 读 test.parquet
      → feature_engineering.engineer_features(is_train=False)
      → utils.prepare_features
      → 加载 .pkl → predict
      → 写 submission.csv
```

---

## 六、你作为新手可以怎么用 Cursor？

- **看代码**：在 Cursor 里打开 `train_quick.py`、`feature_engineering.py`、`utils.py`，边看边对照上面的「每个文件在干什么」。  
- **改配置**：只改 `config.py` 里的数字或列表（如 LAG_FEATURES、ROLLING_WINDOWS、验证集比例），就能改特征和训练方式。  
- **运行**：在终端执行 `./run_train_quick.sh` 或 `./run_train.sh`，看输出里的 MAE/RMSE 和特征重要性。  
- **提交**：跑完 `./run_predict.sh` 后，把生成的 `submission.csv` 上传到 Kaggle 对应比赛页面。

如果你愿意，我可以再按「只看一个文件」的方式，把某一个文件（比如 `feature_engineering.py` 或 `train_quick.py`）逐段用中文讲一遍逻辑。
